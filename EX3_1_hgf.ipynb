{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import tensorflow as tf\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import plotly.express as px\r\n",
    "\r\n",
    "from sklearn import datasets\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\r\n",
    "from sklearn.model_selection import cross_val_score\r\n",
    "\r\n",
    "from keras.models import Sequential, load_model\r\n",
    "from keras.layers import Dense\r\n",
    "from keras.layers import Dropout\r\n",
    "from keras.utils.vis_utils import plot_model\r\n",
    "from keras.utils.np_utils import  to_categorical\r\n",
    "from keras.callbacks import ModelCheckpoint\r\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
    "\r\n",
    "\r\n",
    "# Ignorar Avisos desnecessários\r\n",
    "import warnings\r\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\r\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confere se temos GPU instalada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\r\n",
    "#print(tf.config.experimental.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\r\n",
    "    acc = history.history['accuracy']\r\n",
    "    val_acc = history.history['val_accuracy']\r\n",
    "    loss = history.history['loss']\r\n",
    "    val_loss = history.history['val_loss']\r\n",
    "    x = range(1, len(acc) + 1)\r\n",
    "\r\n",
    "    plt.figure(figsize=(12, 5))\r\n",
    "    plt.subplot(1, 2, 1)\r\n",
    "    plt.plot(x, acc, 'b', label='Training Accuracy')\r\n",
    "    plt.plot(x, val_acc, 'r', label='Validation Accuracy')\r\n",
    "    plt.title('Training and validation Accuracy')\r\n",
    "    plt.subplot(1, 2, 2)\r\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\r\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\r\n",
    "    plt.title('Training and validation loss')\r\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise dos Dados\r\n",
    "\r\n",
    "## Carregando a base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "diagonal": {
          "visible": false
         },
         "dimensions": [
          {
           "axis": {
            "matches": true
           },
           "label": "sepal_width",
           "values": [
            3.5,
            3,
            3.2,
            3.1,
            3.6,
            3.9,
            3.4,
            3.4,
            2.9,
            3.1,
            3.7,
            3.4,
            3,
            3,
            4,
            4.4,
            3.9,
            3.5,
            3.8,
            3.8,
            3.4,
            3.7,
            3.6,
            3.3,
            3.4,
            3,
            3.4,
            3.5,
            3.4,
            3.2,
            3.1,
            3.4,
            4.1,
            4.2,
            3.1,
            3.2,
            3.5,
            3.1,
            3,
            3.4,
            3.5,
            2.3,
            3.2,
            3.5,
            3.8,
            3,
            3.8,
            3.2,
            3.7,
            3.3
           ]
          },
          {
           "axis": {
            "matches": true
           },
           "label": "sepal_length",
           "values": [
            5.1,
            4.9,
            4.7,
            4.6,
            5,
            5.4,
            4.6,
            5,
            4.4,
            4.9,
            5.4,
            4.8,
            4.8,
            4.3,
            5.8,
            5.7,
            5.4,
            5.1,
            5.7,
            5.1,
            5.4,
            5.1,
            4.6,
            5.1,
            4.8,
            5,
            5,
            5.2,
            5.2,
            4.7,
            4.8,
            5.4,
            5.2,
            5.5,
            4.9,
            5,
            5.5,
            4.9,
            4.4,
            5.1,
            5,
            4.5,
            4.4,
            5,
            5.1,
            4.8,
            5.1,
            4.6,
            5.3,
            5
           ]
          },
          {
           "axis": {
            "matches": true
           },
           "label": "petal_width",
           "values": [
            0.2,
            0.2,
            0.2,
            0.2,
            0.2,
            0.4,
            0.3,
            0.2,
            0.2,
            0.1,
            0.2,
            0.2,
            0.1,
            0.1,
            0.2,
            0.4,
            0.4,
            0.3,
            0.3,
            0.3,
            0.2,
            0.4,
            0.2,
            0.5,
            0.2,
            0.2,
            0.4,
            0.2,
            0.2,
            0.2,
            0.2,
            0.4,
            0.1,
            0.2,
            0.1,
            0.2,
            0.2,
            0.1,
            0.2,
            0.2,
            0.3,
            0.3,
            0.2,
            0.6,
            0.4,
            0.3,
            0.2,
            0.2,
            0.2,
            0.2
           ]
          },
          {
           "axis": {
            "matches": true
           },
           "label": "petal_length",
           "values": [
            1.4,
            1.4,
            1.3,
            1.5,
            1.4,
            1.7,
            1.4,
            1.5,
            1.4,
            1.5,
            1.5,
            1.6,
            1.4,
            1.1,
            1.2,
            1.5,
            1.3,
            1.4,
            1.7,
            1.5,
            1.7,
            1.5,
            1,
            1.7,
            1.9,
            1.6,
            1.6,
            1.5,
            1.4,
            1.6,
            1.6,
            1.5,
            1.5,
            1.4,
            1.5,
            1.2,
            1.3,
            1.5,
            1.3,
            1.5,
            1.3,
            1.3,
            1.3,
            1.6,
            1.9,
            1.4,
            1.6,
            1.4,
            1.5,
            1.4
           ]
          }
         ],
         "hovertemplate": "species=setosa<br>%{xaxis.title.text}=%{x}<br>%{yaxis.title.text}=%{y}<extra></extra>",
         "legendgroup": "setosa",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "name": "setosa",
         "showlegend": true,
         "showupperhalf": false,
         "type": "splom"
        },
        {
         "diagonal": {
          "visible": false
         },
         "dimensions": [
          {
           "axis": {
            "matches": true
           },
           "label": "sepal_width",
           "values": [
            3.2,
            3.2,
            3.1,
            2.3,
            2.8,
            2.8,
            3.3,
            2.4,
            2.9,
            2.7,
            2,
            3,
            2.2,
            2.9,
            2.9,
            3.1,
            3,
            2.7,
            2.2,
            2.5,
            3.2,
            2.8,
            2.5,
            2.8,
            2.9,
            3,
            2.8,
            3,
            2.9,
            2.6,
            2.4,
            2.4,
            2.7,
            2.7,
            3,
            3.4,
            3.1,
            2.3,
            3,
            2.5,
            2.6,
            3,
            2.6,
            2.3,
            2.7,
            3,
            2.9,
            2.9,
            2.5,
            2.8
           ]
          },
          {
           "axis": {
            "matches": true
           },
           "label": "sepal_length",
           "values": [
            7,
            6.4,
            6.9,
            5.5,
            6.5,
            5.7,
            6.3,
            4.9,
            6.6,
            5.2,
            5,
            5.9,
            6,
            6.1,
            5.6,
            6.7,
            5.6,
            5.8,
            6.2,
            5.6,
            5.9,
            6.1,
            6.3,
            6.1,
            6.4,
            6.6,
            6.8,
            6.7,
            6,
            5.7,
            5.5,
            5.5,
            5.8,
            6,
            5.4,
            6,
            6.7,
            6.3,
            5.6,
            5.5,
            5.5,
            6.1,
            5.8,
            5,
            5.6,
            5.7,
            5.7,
            6.2,
            5.1,
            5.7
           ]
          },
          {
           "axis": {
            "matches": true
           },
           "label": "petal_width",
           "values": [
            1.4,
            1.5,
            1.5,
            1.3,
            1.5,
            1.3,
            1.6,
            1,
            1.3,
            1.4,
            1,
            1.5,
            1,
            1.4,
            1.3,
            1.4,
            1.5,
            1,
            1.5,
            1.1,
            1.8,
            1.3,
            1.5,
            1.2,
            1.3,
            1.4,
            1.4,
            1.7,
            1.5,
            1,
            1.1,
            1,
            1.2,
            1.6,
            1.5,
            1.6,
            1.5,
            1.3,
            1.3,
            1.3,
            1.2,
            1.4,
            1.2,
            1,
            1.3,
            1.2,
            1.3,
            1.3,
            1.1,
            1.3
           ]
          },
          {
           "axis": {
            "matches": true
           },
           "label": "petal_length",
           "values": [
            4.7,
            4.5,
            4.9,
            4,
            4.6,
            4.5,
            4.7,
            3.3,
            4.6,
            3.9,
            3.5,
            4.2,
            4,
            4.7,
            3.6,
            4.4,
            4.5,
            4.1,
            4.5,
            3.9,
            4.8,
            4,
            4.9,
            4.7,
            4.3,
            4.4,
            4.8,
            5,
            4.5,
            3.5,
            3.8,
            3.7,
            3.9,
            5.1,
            4.5,
            4.5,
            4.7,
            4.4,
            4.1,
            4,
            4.4,
            4.6,
            4,
            3.3,
            4.2,
            4.2,
            4.2,
            4.3,
            3,
            4.1
           ]
          }
         ],
         "hovertemplate": "species=versicolor<br>%{xaxis.title.text}=%{x}<br>%{yaxis.title.text}=%{y}<extra></extra>",
         "legendgroup": "versicolor",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "name": "versicolor",
         "showlegend": true,
         "showupperhalf": false,
         "type": "splom"
        },
        {
         "diagonal": {
          "visible": false
         },
         "dimensions": [
          {
           "axis": {
            "matches": true
           },
           "label": "sepal_width",
           "values": [
            3.3,
            2.7,
            3,
            2.9,
            3,
            3,
            2.5,
            2.9,
            2.5,
            3.6,
            3.2,
            2.7,
            3,
            2.5,
            2.8,
            3.2,
            3,
            3.8,
            2.6,
            2.2,
            3.2,
            2.8,
            2.8,
            2.7,
            3.3,
            3.2,
            2.8,
            3,
            2.8,
            3,
            2.8,
            3.8,
            2.8,
            2.8,
            2.6,
            3,
            3.4,
            3.1,
            3,
            3.1,
            3.1,
            3.1,
            2.7,
            3.2,
            3.3,
            3,
            2.5,
            3,
            3.4,
            3
           ]
          },
          {
           "axis": {
            "matches": true
           },
           "label": "sepal_length",
           "values": [
            6.3,
            5.8,
            7.1,
            6.3,
            6.5,
            7.6,
            4.9,
            7.3,
            6.7,
            7.2,
            6.5,
            6.4,
            6.8,
            5.7,
            5.8,
            6.4,
            6.5,
            7.7,
            7.7,
            6,
            6.9,
            5.6,
            7.7,
            6.3,
            6.7,
            7.2,
            6.2,
            6.1,
            6.4,
            7.2,
            7.4,
            7.9,
            6.4,
            6.3,
            6.1,
            7.7,
            6.3,
            6.4,
            6,
            6.9,
            6.7,
            6.9,
            5.8,
            6.8,
            6.7,
            6.7,
            6.3,
            6.5,
            6.2,
            5.9
           ]
          },
          {
           "axis": {
            "matches": true
           },
           "label": "petal_width",
           "values": [
            2.5,
            1.9,
            2.1,
            1.8,
            2.2,
            2.1,
            1.7,
            1.8,
            1.8,
            2.5,
            2,
            1.9,
            2.1,
            2,
            2.4,
            2.3,
            1.8,
            2.2,
            2.3,
            1.5,
            2.3,
            2,
            2,
            1.8,
            2.1,
            1.8,
            1.8,
            1.8,
            2.1,
            1.6,
            1.9,
            2,
            2.2,
            1.5,
            1.4,
            2.3,
            2.4,
            1.8,
            1.8,
            2.1,
            2.4,
            2.3,
            1.9,
            2.3,
            2.5,
            2.3,
            1.9,
            2,
            2.3,
            1.8
           ]
          },
          {
           "axis": {
            "matches": true
           },
           "label": "petal_length",
           "values": [
            6,
            5.1,
            5.9,
            5.6,
            5.8,
            6.6,
            4.5,
            6.3,
            5.8,
            6.1,
            5.1,
            5.3,
            5.5,
            5,
            5.1,
            5.3,
            5.5,
            6.7,
            6.9,
            5,
            5.7,
            4.9,
            6.7,
            4.9,
            5.7,
            6,
            4.8,
            4.9,
            5.6,
            5.8,
            6.1,
            6.4,
            5.6,
            5.1,
            5.6,
            6.1,
            5.6,
            5.5,
            4.8,
            5.4,
            5.6,
            5.1,
            5.1,
            5.9,
            5.7,
            5.2,
            5,
            5.2,
            5.4,
            5.1
           ]
          }
         ],
         "hovertemplate": "species=virginica<br>%{xaxis.title.text}=%{x}<br>%{yaxis.title.text}=%{y}<extra></extra>",
         "legendgroup": "virginica",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "name": "virginica",
         "showlegend": true,
         "showupperhalf": false,
         "type": "splom"
        }
       ],
       "layout": {
        "dragmode": "select",
        "height": 600,
        "legend": {
         "title": {
          "text": "species"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Iris Data set"
        },
        "width": 1000
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = px.data.iris()\r\n",
    "fig = px.scatter_matrix(df, dimensions=[\"sepal_width\", \"sepal_length\", \"petal_width\", \"petal_length\"], color=\"species\")\r\n",
    "fig.update_traces(diagonal_visible=False, showupperhalf=False)\r\n",
    "fig.update_layout(title='Iris Data set', width=1000, height=600)\r\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = iris.feature_names\r\n",
    "X = iris.data\r\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = iris.target_names\r\n",
    "y = iris.target\r\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y)\r\n",
    "plt.title('Distribuição da variável Target')\r\n",
    "plt.xlabel('Target')\r\n",
    "plt.xticks(ticks=range(0,3), labels=classes)\r\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padronizando os dados com o MinMaxScaler do SKlearn. \r\n",
    "### Dados padronizados entre 0 e 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.625     , 0.06779661, 0.04166667],\n",
       "       [0.16666667, 0.41666667, 0.06779661, 0.04166667],\n",
       "       [0.11111111, 0.5       , 0.05084746, 0.04166667],\n",
       "       [0.08333333, 0.45833333, 0.08474576, 0.04166667],\n",
       "       [0.19444444, 0.66666667, 0.06779661, 0.04166667]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\r\n",
    "X = scaler.fit_transform(X)\r\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo a Base de Dados entre Treino e Teste, com 20% para os testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformando a variável de resposta em \"One-hot vector\" para utilizá-la no modelo de MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.shape[1]\r\n",
    "num_classes = len(np.unique(y)) # y.shape[1]\r\n",
    "y_train = to_categorical(y_train)\r\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de MLP\r\n",
    "\r\n",
    "## Criando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\r\n",
    "model.add(Dense(8, input_dim=num_features, activation='relu'))\r\n",
    "model.add(Dense(num_classes , activation='softmax'))\r\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilando e treinando o modelo. \r\n",
    "### Vamos utilizar a função de Callback ModelCheckPointer para salvar o modelo com a melhor accuracia na base de validação (que é a mesma de teste final pois temos uma base muito pequena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 1.0621 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70000, saving model to .\\modelo_mlp_ex3_1.hdf5\n",
      "15/15 [==============================] - 0s 18ms/step - loss: 0.9319 - accuracy: 0.6500 - val_loss: 0.8695 - val_accuracy: 0.7000\n",
      "Epoch 2/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.9086 - accuracy: 0.7500\n",
      "Epoch 00002: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.9041 - accuracy: 0.6500 - val_loss: 0.8489 - val_accuracy: 0.7000\n",
      "Epoch 3/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.7126 - accuracy: 0.8750\n",
      "Epoch 00003: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8822 - accuracy: 0.6500 - val_loss: 0.8305 - val_accuracy: 0.7000\n",
      "Epoch 4/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.9587 - accuracy: 0.5000\n",
      "Epoch 00004: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8622 - accuracy: 0.6500 - val_loss: 0.8143 - val_accuracy: 0.7000\n",
      "Epoch 5/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.6662 - accuracy: 0.7500\n",
      "Epoch 00005: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.8444 - accuracy: 0.6583 - val_loss: 0.8001 - val_accuracy: 0.7000\n",
      "Epoch 6/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.6057 - accuracy: 0.8750\n",
      "Epoch 00006: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8280 - accuracy: 0.6583 - val_loss: 0.7859 - val_accuracy: 0.7000\n",
      "Epoch 7/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.6821 - accuracy: 0.7500\n",
      "Epoch 00007: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.8124 - accuracy: 0.6583 - val_loss: 0.7729 - val_accuracy: 0.7000\n",
      "Epoch 8/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.8847 - accuracy: 0.5000\n",
      "Epoch 00008: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7975 - accuracy: 0.6583 - val_loss: 0.7592 - val_accuracy: 0.7000\n",
      "Epoch 9/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.7804 - accuracy: 0.7500\n",
      "Epoch 00009: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7823 - accuracy: 0.6583 - val_loss: 0.7467 - val_accuracy: 0.7000\n",
      "Epoch 10/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.8623 - accuracy: 0.6250\n",
      "Epoch 00010: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7685 - accuracy: 0.6583 - val_loss: 0.7333 - val_accuracy: 0.7000\n",
      "Epoch 11/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.7232 - accuracy: 1.0000\n",
      "Epoch 00011: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7536 - accuracy: 0.6583 - val_loss: 0.7197 - val_accuracy: 0.7000\n",
      "Epoch 12/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.7235 - accuracy: 0.6250\n",
      "Epoch 00012: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7388 - accuracy: 0.6583 - val_loss: 0.7068 - val_accuracy: 0.7000\n",
      "Epoch 13/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.7756 - accuracy: 0.5000\n",
      "Epoch 00013: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7243 - accuracy: 0.6583 - val_loss: 0.6934 - val_accuracy: 0.7000\n",
      "Epoch 14/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.7257 - accuracy: 0.6250\n",
      "Epoch 00014: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.7097 - accuracy: 0.6583 - val_loss: 0.6796 - val_accuracy: 0.7000\n",
      "Epoch 15/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.6692 - accuracy: 0.8750\n",
      "Epoch 00015: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6960 - accuracy: 0.6583 - val_loss: 0.6652 - val_accuracy: 0.7000\n",
      "Epoch 16/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.6176 - accuracy: 0.7500\n",
      "Epoch 00016: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6794 - accuracy: 0.6583 - val_loss: 0.6519 - val_accuracy: 0.7000\n",
      "Epoch 17/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.7553 - accuracy: 0.5000\n",
      "Epoch 00017: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.6583 - val_loss: 0.6375 - val_accuracy: 0.7000\n",
      "Epoch 18/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.7540 - accuracy: 0.5000\n",
      "Epoch 00018: val_accuracy did not improve from 0.70000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6482 - accuracy: 0.6583 - val_loss: 0.6178 - val_accuracy: 0.7000\n",
      "Epoch 19/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.6876 - accuracy: 0.6250\n",
      "Epoch 00019: val_accuracy improved from 0.70000 to 0.73333, saving model to .\\modelo_mlp_ex3_1.hdf5\n",
      "15/15 [==============================] - 0s 10ms/step - loss: 0.6249 - accuracy: 0.6750 - val_loss: 0.5970 - val_accuracy: 0.7333\n",
      "Epoch 20/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.6721 - accuracy: 0.6250\n",
      "Epoch 00020: val_accuracy did not improve from 0.73333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.7250 - val_loss: 0.5841 - val_accuracy: 0.7333\n",
      "Epoch 21/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.5685 - accuracy: 0.8750\n",
      "Epoch 00021: val_accuracy did not improve from 0.73333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5917 - accuracy: 0.7417 - val_loss: 0.5714 - val_accuracy: 0.7333\n",
      "Epoch 22/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.6776 - accuracy: 0.6250\n",
      "Epoch 00022: val_accuracy improved from 0.73333 to 0.76667, saving model to .\\modelo_mlp_ex3_1.hdf5\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.7417 - val_loss: 0.5588 - val_accuracy: 0.7667\n",
      "Epoch 23/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.7326 - accuracy: 0.5000\n",
      "Epoch 00023: val_accuracy improved from 0.76667 to 0.80000, saving model to .\\modelo_mlp_ex3_1.hdf5\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5668 - accuracy: 0.7417 - val_loss: 0.5480 - val_accuracy: 0.8000\n",
      "Epoch 24/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.6760 - accuracy: 0.6250\n",
      "Epoch 00024: val_accuracy improved from 0.80000 to 0.90000, saving model to .\\modelo_mlp_ex3_1.hdf5\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.7833 - val_loss: 0.5374 - val_accuracy: 0.9000\n",
      "Epoch 25/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.5031 - accuracy: 0.8750\n",
      "Epoch 00025: val_accuracy did not improve from 0.90000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.8583 - val_loss: 0.5272 - val_accuracy: 0.9000\n",
      "Epoch 26/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.5516 - accuracy: 0.8750\n",
      "Epoch 00026: val_accuracy did not improve from 0.90000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.8000 - val_loss: 0.5161 - val_accuracy: 0.8000\n",
      "Epoch 27/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.5569 - accuracy: 0.7500\n",
      "Epoch 00027: val_accuracy did not improve from 0.90000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7917 - val_loss: 0.5072 - val_accuracy: 0.9000\n",
      "Epoch 28/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.5815 - accuracy: 0.8750\n",
      "Epoch 00028: val_accuracy did not improve from 0.90000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.8750 - val_loss: 0.4988 - val_accuracy: 0.9000\n",
      "Epoch 29/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3891 - accuracy: 0.8750\n",
      "Epoch 00029: val_accuracy did not improve from 0.90000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.8750 - val_loss: 0.4904 - val_accuracy: 0.9000\n",
      "Epoch 30/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.6534 - accuracy: 0.6250\n",
      "Epoch 00030: val_accuracy did not improve from 0.90000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.8833 - val_loss: 0.4828 - val_accuracy: 0.9000\n",
      "Epoch 31/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.5471 - accuracy: 0.7500\n",
      "Epoch 00031: val_accuracy did not improve from 0.90000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.8750 - val_loss: 0.4751 - val_accuracy: 0.9000\n",
      "Epoch 32/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4569 - accuracy: 1.0000\n",
      "Epoch 00032: val_accuracy did not improve from 0.90000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.8750 - val_loss: 0.4673 - val_accuracy: 0.9000\n",
      "Epoch 33/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4554 - accuracy: 0.8750\n",
      "Epoch 00033: val_accuracy did not improve from 0.90000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.8750 - val_loss: 0.4609 - val_accuracy: 0.9000\n",
      "Epoch 34/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4991 - accuracy: 0.8750\n",
      "Epoch 00034: val_accuracy did not improve from 0.90000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.9083 - val_loss: 0.4555 - val_accuracy: 0.9000\n",
      "Epoch 35/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4530 - accuracy: 0.8750\n",
      "Epoch 00035: val_accuracy did not improve from 0.90000\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.9083 - val_loss: 0.4487 - val_accuracy: 0.9000\n",
      "Epoch 36/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.5332 - accuracy: 0.8750\n",
      "Epoch 00036: val_accuracy improved from 0.90000 to 0.93333, saving model to .\\modelo_mlp_ex3_1.hdf5\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.9083 - val_loss: 0.4430 - val_accuracy: 0.9333\n",
      "Epoch 37/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3723 - accuracy: 0.8750\n",
      "Epoch 00037: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.9250 - val_loss: 0.4374 - val_accuracy: 0.9000\n",
      "Epoch 38/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4779 - accuracy: 1.0000\n",
      "Epoch 00038: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.9250 - val_loss: 0.4319 - val_accuracy: 0.9000\n",
      "Epoch 39/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4872 - accuracy: 0.8750\n",
      "Epoch 00039: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.9250 - val_loss: 0.4271 - val_accuracy: 0.9333\n",
      "Epoch 40/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3997 - accuracy: 1.0000\n",
      "Epoch 00040: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4394 - accuracy: 0.9250 - val_loss: 0.4222 - val_accuracy: 0.9333\n",
      "Epoch 41/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.5378 - accuracy: 1.0000\n",
      "Epoch 00041: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.9333 - val_loss: 0.4173 - val_accuracy: 0.9333\n",
      "Epoch 42/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4887 - accuracy: 1.0000\n",
      "Epoch 00042: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.9250 - val_loss: 0.4123 - val_accuracy: 0.9333\n",
      "Epoch 43/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3437 - accuracy: 1.0000\n",
      "Epoch 00043: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.9333 - val_loss: 0.4081 - val_accuracy: 0.9333\n",
      "Epoch 44/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4602 - accuracy: 0.8750\n",
      "Epoch 00044: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.9417 - val_loss: 0.4042 - val_accuracy: 0.9333\n",
      "Epoch 45/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3655 - accuracy: 1.0000\n",
      "Epoch 00045: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.9333 - val_loss: 0.3994 - val_accuracy: 0.9333\n",
      "Epoch 46/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.5003 - accuracy: 0.8750\n",
      "Epoch 00046: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.9333 - val_loss: 0.3949 - val_accuracy: 0.9333\n",
      "Epoch 47/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4469 - accuracy: 1.0000\n",
      "Epoch 00047: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.9333 - val_loss: 0.3911 - val_accuracy: 0.9333\n",
      "Epoch 48/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4618 - accuracy: 0.7500\n",
      "Epoch 00048: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.9500 - val_loss: 0.3881 - val_accuracy: 0.9333\n",
      "Epoch 49/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3315 - accuracy: 1.0000\n",
      "Epoch 00049: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.4010 - accuracy: 0.9500 - val_loss: 0.3842 - val_accuracy: 0.9333\n",
      "Epoch 50/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4371 - accuracy: 0.8750\n",
      "Epoch 00050: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3973 - accuracy: 0.9500 - val_loss: 0.3806 - val_accuracy: 0.9333\n",
      "Epoch 51/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4319 - accuracy: 1.0000\n",
      "Epoch 00051: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.9500 - val_loss: 0.3770 - val_accuracy: 0.9333\n",
      "Epoch 52/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4184 - accuracy: 1.0000\n",
      "Epoch 00052: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3902 - accuracy: 0.9500 - val_loss: 0.3732 - val_accuracy: 0.9333\n",
      "Epoch 53/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3701 - accuracy: 1.0000\n",
      "Epoch 00053: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.9500 - val_loss: 0.3695 - val_accuracy: 0.9333\n",
      "Epoch 54/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4965 - accuracy: 1.0000\n",
      "Epoch 00054: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.9500 - val_loss: 0.3666 - val_accuracy: 0.9333\n",
      "Epoch 55/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3142 - accuracy: 1.0000\n",
      "Epoch 00055: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.3799 - accuracy: 0.9500 - val_loss: 0.3632 - val_accuracy: 0.9333\n",
      "Epoch 56/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4097 - accuracy: 1.0000\n",
      "Epoch 00056: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3761 - accuracy: 0.9500 - val_loss: 0.3596 - val_accuracy: 0.9333\n",
      "Epoch 57/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4524 - accuracy: 1.0000\n",
      "Epoch 00057: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3732 - accuracy: 0.9500 - val_loss: 0.3561 - val_accuracy: 0.9333\n",
      "Epoch 58/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3946 - accuracy: 1.0000\n",
      "Epoch 00058: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.9500 - val_loss: 0.3531 - val_accuracy: 0.9333\n",
      "Epoch 59/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3396 - accuracy: 0.8750\n",
      "Epoch 00059: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.9583 - val_loss: 0.3500 - val_accuracy: 0.9333\n",
      "Epoch 60/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4235 - accuracy: 0.8750\n",
      "Epoch 00060: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.9583 - val_loss: 0.3470 - val_accuracy: 0.9333\n",
      "Epoch 61/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3389 - accuracy: 1.0000\n",
      "Epoch 00061: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3599 - accuracy: 0.9583 - val_loss: 0.3439 - val_accuracy: 0.9333\n",
      "Epoch 62/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1728 - accuracy: 1.0000\n",
      "Epoch 00062: val_accuracy did not improve from 0.93333\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3571 - accuracy: 0.9583 - val_loss: 0.3410 - val_accuracy: 0.9333\n",
      "Epoch 63/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4290 - accuracy: 1.0000\n",
      "Epoch 00063: val_accuracy improved from 0.93333 to 0.96667, saving model to .\\modelo_mlp_ex3_1.hdf5\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.9583 - val_loss: 0.3380 - val_accuracy: 0.9667\n",
      "Epoch 64/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2908 - accuracy: 1.0000\n",
      "Epoch 00064: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.9583 - val_loss: 0.3348 - val_accuracy: 0.9333\n",
      "Epoch 65/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2005 - accuracy: 1.0000\n",
      "Epoch 00065: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.9583 - val_loss: 0.3318 - val_accuracy: 0.9333\n",
      "Epoch 66/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2758 - accuracy: 1.0000\n",
      "Epoch 00066: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.9583 - val_loss: 0.3287 - val_accuracy: 0.9333\n",
      "Epoch 67/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3373 - accuracy: 0.8750\n",
      "Epoch 00067: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.9583 - val_loss: 0.3261 - val_accuracy: 0.9667\n",
      "Epoch 68/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2865 - accuracy: 0.8750\n",
      "Epoch 00068: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 0.3402 - accuracy: 0.9583 - val_loss: 0.3230 - val_accuracy: 0.9333\n",
      "Epoch 69/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2837 - accuracy: 1.0000\n",
      "Epoch 00069: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.9583 - val_loss: 0.3203 - val_accuracy: 0.9667\n",
      "Epoch 70/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3557 - accuracy: 1.0000\n",
      "Epoch 00070: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.9583 - val_loss: 0.3177 - val_accuracy: 0.9667\n",
      "Epoch 71/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4461 - accuracy: 1.0000\n",
      "Epoch 00071: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.9583 - val_loss: 0.3145 - val_accuracy: 0.9667\n",
      "Epoch 72/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3245 - accuracy: 0.8750\n",
      "Epoch 00072: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3287 - accuracy: 0.9667 - val_loss: 0.3122 - val_accuracy: 0.9667\n",
      "Epoch 73/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4195 - accuracy: 0.8750\n",
      "Epoch 00073: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.3248 - accuracy: 0.9667 - val_loss: 0.3093 - val_accuracy: 0.9667\n",
      "Epoch 74/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3283 - accuracy: 1.0000\n",
      "Epoch 00074: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.9583 - val_loss: 0.3065 - val_accuracy: 0.9667\n",
      "Epoch 75/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2976 - accuracy: 0.8750\n",
      "Epoch 00075: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3210 - accuracy: 0.9583 - val_loss: 0.3038 - val_accuracy: 0.9667\n",
      "Epoch 76/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.4431 - accuracy: 1.0000\n",
      "Epoch 00076: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.9583 - val_loss: 0.3015 - val_accuracy: 0.9667\n",
      "Epoch 77/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2945 - accuracy: 1.0000\n",
      "Epoch 00077: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.9583 - val_loss: 0.2987 - val_accuracy: 0.9667\n",
      "Epoch 78/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2546 - accuracy: 1.0000\n",
      "Epoch 00078: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3117 - accuracy: 0.9667 - val_loss: 0.2962 - val_accuracy: 0.9667\n",
      "Epoch 79/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3680 - accuracy: 1.0000\n",
      "Epoch 00079: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3087 - accuracy: 0.9667 - val_loss: 0.2938 - val_accuracy: 0.9667\n",
      "Epoch 80/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3514 - accuracy: 0.8750\n",
      "Epoch 00080: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3064 - accuracy: 0.9667 - val_loss: 0.2915 - val_accuracy: 0.9667\n",
      "Epoch 81/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2676 - accuracy: 1.0000\n",
      "Epoch 00081: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3035 - accuracy: 0.9667 - val_loss: 0.2886 - val_accuracy: 0.9667\n",
      "Epoch 82/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2034 - accuracy: 1.0000\n",
      "Epoch 00082: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.3013 - accuracy: 0.9667 - val_loss: 0.2861 - val_accuracy: 0.9667\n",
      "Epoch 83/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3213 - accuracy: 1.0000\n",
      "Epoch 00083: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2996 - accuracy: 0.9583 - val_loss: 0.2837 - val_accuracy: 0.9667\n",
      "Epoch 84/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2881 - accuracy: 1.0000\n",
      "Epoch 00084: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2969 - accuracy: 0.9583 - val_loss: 0.2816 - val_accuracy: 0.9667\n",
      "Epoch 85/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2191 - accuracy: 1.0000\n",
      "Epoch 00085: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2937 - accuracy: 0.9583 - val_loss: 0.2791 - val_accuracy: 0.9667\n",
      "Epoch 86/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2284 - accuracy: 1.0000\n",
      "Epoch 00086: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.9667 - val_loss: 0.2768 - val_accuracy: 0.9667\n",
      "Epoch 87/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2362 - accuracy: 1.0000\n",
      "Epoch 00087: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2888 - accuracy: 0.9583 - val_loss: 0.2746 - val_accuracy: 0.9667\n",
      "Epoch 88/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2518 - accuracy: 1.0000\n",
      "Epoch 00088: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.2870 - accuracy: 0.9583 - val_loss: 0.2725 - val_accuracy: 0.9667\n",
      "Epoch 89/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2771 - accuracy: 1.0000\n",
      "Epoch 00089: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.9583 - val_loss: 0.2700 - val_accuracy: 0.9667\n",
      "Epoch 90/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2427 - accuracy: 1.0000\n",
      "Epoch 00090: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.9583 - val_loss: 0.2678 - val_accuracy: 0.9667\n",
      "Epoch 91/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1395 - accuracy: 1.0000\n",
      "Epoch 00091: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.9583 - val_loss: 0.2656 - val_accuracy: 0.9667\n",
      "Epoch 92/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2467 - accuracy: 0.8750\n",
      "Epoch 00092: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.9583 - val_loss: 0.2634 - val_accuracy: 0.9667\n",
      "Epoch 93/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1649 - accuracy: 1.0000\n",
      "Epoch 00093: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2754 - accuracy: 0.9583 - val_loss: 0.2613 - val_accuracy: 0.9667\n",
      "Epoch 94/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2958 - accuracy: 1.0000\n",
      "Epoch 00094: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2726 - accuracy: 0.9583 - val_loss: 0.2591 - val_accuracy: 0.9667\n",
      "Epoch 95/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2998 - accuracy: 1.0000\n",
      "Epoch 00095: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2707 - accuracy: 0.9583 - val_loss: 0.2571 - val_accuracy: 0.9667\n",
      "Epoch 96/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2489 - accuracy: 1.0000\n",
      "Epoch 00096: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2695 - accuracy: 0.9583 - val_loss: 0.2551 - val_accuracy: 0.9667\n",
      "Epoch 97/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1554 - accuracy: 1.0000\n",
      "Epoch 00097: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2662 - accuracy: 0.9667 - val_loss: 0.2529 - val_accuracy: 0.9667\n",
      "Epoch 98/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3386 - accuracy: 0.8750\n",
      "Epoch 00098: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2643 - accuracy: 0.9583 - val_loss: 0.2510 - val_accuracy: 0.9667\n",
      "Epoch 99/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3355 - accuracy: 0.7500\n",
      "Epoch 00099: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2618 - accuracy: 0.9583 - val_loss: 0.2489 - val_accuracy: 0.9667\n",
      "Epoch 100/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1642 - accuracy: 1.0000\n",
      "Epoch 00100: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2598 - accuracy: 0.9583 - val_loss: 0.2468 - val_accuracy: 0.9667\n",
      "Epoch 101/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2501 - accuracy: 1.0000\n",
      "Epoch 00101: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2585 - accuracy: 0.9583 - val_loss: 0.2450 - val_accuracy: 0.9667\n",
      "Epoch 102/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1973 - accuracy: 1.0000\n",
      "Epoch 00102: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.9583 - val_loss: 0.2429 - val_accuracy: 0.9667\n",
      "Epoch 103/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2582 - accuracy: 1.0000\n",
      "Epoch 00103: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2536 - accuracy: 0.9583 - val_loss: 0.2410 - val_accuracy: 0.9667\n",
      "Epoch 104/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1986 - accuracy: 1.0000\n",
      "Epoch 00104: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.9583 - val_loss: 0.2391 - val_accuracy: 0.9667\n",
      "Epoch 105/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1975 - accuracy: 1.0000\n",
      "Epoch 00105: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2498 - accuracy: 0.9583 - val_loss: 0.2372 - val_accuracy: 0.9667\n",
      "Epoch 106/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1740 - accuracy: 1.0000\n",
      "Epoch 00106: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2477 - accuracy: 0.9583 - val_loss: 0.2353 - val_accuracy: 0.9667\n",
      "Epoch 107/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2905 - accuracy: 1.0000\n",
      "Epoch 00107: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.9583 - val_loss: 0.2335 - val_accuracy: 0.9667\n",
      "Epoch 108/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2693 - accuracy: 1.0000\n",
      "Epoch 00108: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.9583 - val_loss: 0.2320 - val_accuracy: 0.9667\n",
      "Epoch 109/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2668 - accuracy: 1.0000\n",
      "Epoch 00109: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2422 - accuracy: 0.9583 - val_loss: 0.2300 - val_accuracy: 0.9667\n",
      "Epoch 110/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1733 - accuracy: 1.0000\n",
      "Epoch 00110: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2400 - accuracy: 0.9583 - val_loss: 0.2282 - val_accuracy: 0.9667\n",
      "Epoch 111/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3079 - accuracy: 0.8750\n",
      "Epoch 00111: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2384 - accuracy: 0.9583 - val_loss: 0.2265 - val_accuracy: 0.9667\n",
      "Epoch 112/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2431 - accuracy: 1.0000\n",
      "Epoch 00112: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.9583 - val_loss: 0.2248 - val_accuracy: 0.9667\n",
      "Epoch 113/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2239 - accuracy: 1.0000\n",
      "Epoch 00113: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2344 - accuracy: 0.9583 - val_loss: 0.2231 - val_accuracy: 0.9667\n",
      "Epoch 114/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2761 - accuracy: 1.0000\n",
      "Epoch 00114: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2335 - accuracy: 0.9583 - val_loss: 0.2213 - val_accuracy: 0.9667\n",
      "Epoch 115/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3465 - accuracy: 1.0000\n",
      "Epoch 00115: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2311 - accuracy: 0.9583 - val_loss: 0.2197 - val_accuracy: 0.9667\n",
      "Epoch 116/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2696 - accuracy: 0.8750\n",
      "Epoch 00116: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2295 - accuracy: 0.9583 - val_loss: 0.2184 - val_accuracy: 0.9667\n",
      "Epoch 117/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1272 - accuracy: 1.0000\n",
      "Epoch 00117: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2274 - accuracy: 0.9583 - val_loss: 0.2164 - val_accuracy: 0.9667\n",
      "Epoch 118/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3919 - accuracy: 0.8750\n",
      "Epoch 00118: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2258 - accuracy: 0.9583 - val_loss: 0.2148 - val_accuracy: 0.9667\n",
      "Epoch 119/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1999 - accuracy: 1.0000\n",
      "Epoch 00119: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2240 - accuracy: 0.9583 - val_loss: 0.2131 - val_accuracy: 0.9667\n",
      "Epoch 120/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3332 - accuracy: 1.0000\n",
      "Epoch 00120: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2224 - accuracy: 0.9583 - val_loss: 0.2117 - val_accuracy: 0.9667\n",
      "Epoch 121/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1829 - accuracy: 0.8750\n",
      "Epoch 00121: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2209 - accuracy: 0.9583 - val_loss: 0.2102 - val_accuracy: 0.9667\n",
      "Epoch 122/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1848 - accuracy: 1.0000\n",
      "Epoch 00122: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2189 - accuracy: 0.9583 - val_loss: 0.2086 - val_accuracy: 0.9667\n",
      "Epoch 123/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2080 - accuracy: 1.0000\n",
      "Epoch 00123: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2182 - accuracy: 0.9583 - val_loss: 0.2074 - val_accuracy: 0.9667\n",
      "Epoch 124/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3660 - accuracy: 1.0000\n",
      "Epoch 00124: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2155 - accuracy: 0.9583 - val_loss: 0.2056 - val_accuracy: 0.9667\n",
      "Epoch 125/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2291 - accuracy: 1.0000\n",
      "Epoch 00125: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2142 - accuracy: 0.9583 - val_loss: 0.2041 - val_accuracy: 0.9667\n",
      "Epoch 126/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1657 - accuracy: 1.0000\n",
      "Epoch 00126: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2128 - accuracy: 0.9667 - val_loss: 0.2026 - val_accuracy: 0.9667\n",
      "Epoch 127/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2094 - accuracy: 1.0000\n",
      "Epoch 00127: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9583 - val_loss: 0.2015 - val_accuracy: 0.9667\n",
      "Epoch 128/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3048 - accuracy: 1.0000\n",
      "Epoch 00128: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2099 - accuracy: 0.9583 - val_loss: 0.1998 - val_accuracy: 0.9667\n",
      "Epoch 129/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1919 - accuracy: 1.0000\n",
      "Epoch 00129: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2088 - accuracy: 0.9583 - val_loss: 0.1988 - val_accuracy: 0.9667\n",
      "Epoch 130/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2476 - accuracy: 1.0000\n",
      "Epoch 00130: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9583 - val_loss: 0.1975 - val_accuracy: 0.9667\n",
      "Epoch 131/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1563 - accuracy: 1.0000\n",
      "Epoch 00131: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2063 - accuracy: 0.9667 - val_loss: 0.1956 - val_accuracy: 0.9667\n",
      "Epoch 132/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3691 - accuracy: 0.7500\n",
      "Epoch 00132: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2035 - accuracy: 0.9667 - val_loss: 0.1943 - val_accuracy: 0.9667\n",
      "Epoch 133/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1051 - accuracy: 1.0000\n",
      "Epoch 00133: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2025 - accuracy: 0.9667 - val_loss: 0.1930 - val_accuracy: 0.9667\n",
      "Epoch 134/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1848 - accuracy: 1.0000\n",
      "Epoch 00134: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 0.9667 - val_loss: 0.1921 - val_accuracy: 0.9667\n",
      "Epoch 135/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1573 - accuracy: 1.0000\n",
      "Epoch 00135: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1998 - accuracy: 0.9583 - val_loss: 0.1905 - val_accuracy: 0.9667\n",
      "Epoch 136/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1448 - accuracy: 1.0000\n",
      "Epoch 00136: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1984 - accuracy: 0.9583 - val_loss: 0.1897 - val_accuracy: 0.9667\n",
      "Epoch 137/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1762 - accuracy: 1.0000\n",
      "Epoch 00137: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1975 - accuracy: 0.9667 - val_loss: 0.1878 - val_accuracy: 0.9667\n",
      "Epoch 138/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2096 - accuracy: 1.0000\n",
      "Epoch 00138: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9667 - val_loss: 0.1867 - val_accuracy: 0.9667\n",
      "Epoch 139/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2456 - accuracy: 0.8750\n",
      "Epoch 00139: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9667 - val_loss: 0.1853 - val_accuracy: 0.9667\n",
      "Epoch 140/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.0936 - accuracy: 1.0000\n",
      "Epoch 00140: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9667 - val_loss: 0.1843 - val_accuracy: 0.9667\n",
      "Epoch 141/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.0729 - accuracy: 1.0000\n",
      "Epoch 00141: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1911 - accuracy: 0.9667 - val_loss: 0.1834 - val_accuracy: 0.9667\n",
      "Epoch 142/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2205 - accuracy: 0.8750\n",
      "Epoch 00142: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1900 - accuracy: 0.9667 - val_loss: 0.1822 - val_accuracy: 0.9667\n",
      "Epoch 143/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2607 - accuracy: 1.0000\n",
      "Epoch 00143: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 0.1900 - accuracy: 0.9583 - val_loss: 0.1813 - val_accuracy: 0.9667\n",
      "Epoch 144/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.2178 - accuracy: 1.0000\n",
      "Epoch 00144: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 0.9667 - val_loss: 0.1795 - val_accuracy: 0.9667\n",
      "Epoch 145/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1856 - accuracy: 1.0000\n",
      "Epoch 00145: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1864 - accuracy: 0.9667 - val_loss: 0.1789 - val_accuracy: 0.9667\n",
      "Epoch 146/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1170 - accuracy: 1.0000\n",
      "Epoch 00146: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1850 - accuracy: 0.9667 - val_loss: 0.1777 - val_accuracy: 0.9667\n",
      "Epoch 147/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.1802 - accuracy: 1.0000\n",
      "Epoch 00147: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1842 - accuracy: 0.9667 - val_loss: 0.1768 - val_accuracy: 0.9667\n",
      "Epoch 148/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.0677 - accuracy: 1.0000\n",
      "Epoch 00148: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1829 - accuracy: 0.9667 - val_loss: 0.1751 - val_accuracy: 0.9667\n",
      "Epoch 149/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.3506 - accuracy: 0.8750\n",
      "Epoch 00149: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1814 - accuracy: 0.9667 - val_loss: 0.1742 - val_accuracy: 0.9667\n",
      "Epoch 150/150\n",
      " 1/15 [=>............................] - ETA: 0s - loss: 0.0784 - accuracy: 1.0000\n",
      "Epoch 00150: val_accuracy did not improve from 0.96667\n",
      "15/15 [==============================] - 0s 3ms/step - loss: 0.1817 - accuracy: 0.9667 - val_loss: 0.1743 - val_accuracy: 0.9667\n",
      "Wall time: 7.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\r\n",
    "checkpointer = ModelCheckpoint(filepath='./modelo_mlp_ex3_1.hdf5', verbose=1,  save_best_only=True, monitor='val_accuracy')\r\n",
    "\r\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=150, batch_size=8, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfico comparativo de Acurácia e Perda no treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o melhor modelo salvo e apresentando a acurácia do Treino e do Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./modelo_mlp_ex3_1.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3520 - accuracy: 0.9583\n",
      "\n",
      "Acuracia do Treino: 95.83%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_train, y_train)\r\n",
    "print()\r\n",
    "print(f\"Acuracia do Treino: {round(scores[1]*100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1000us/step - loss: 0.3380 - accuracy: 0.9667\n",
      "\n",
      "Acuracia da Validação: 96.67%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\r\n",
    "print()\r\n",
    "print(f\"Acuracia da Validação: {round(scores[1]*100,2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conferindo o modelo final com uma Validação Cruzada (Cross Validation) usando 10 amostras. Neste caso vamos usar toda a base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(8, input_dim=4, activation='relu'))\r\n",
    "    model.add(Dense(3 , activation='softmax'))\r\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
    "    \r\n",
    "    return model\r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 610 calls to <function Model.make_test_function.<locals>.test_function at 0x0000011EAC2DDEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x0000011DC92C0550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x0000011EB44E9CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000011EB5A2A790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000011EAC33A3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000011DC7AD7280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000011EB72FC5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000011EB44E9670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Accuracy : 0.93 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_model, epochs=150, batch_size=8, verbose=0)\r\n",
    "y = to_categorical(y)\r\n",
    "scores = cross_val_score(estimator, X, y, cv=10, n_jobs=1)\r\n",
    "print()\r\n",
    "print(\"Accuracy : {:0.2f} (+/- {:0.2f})\".format(scores.mean(), scores.std()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c24c9dacf042e5cf8b743bae11b2cef3a95983df3bc5153773d9ffef1d5207d2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tf-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}